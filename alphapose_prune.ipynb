{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.seresnet.FastPose import createModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.opt import opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.loadModel = \"exp/ceiling_sparse_duc_se/5e-6/5e-6_best_auc.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  createModel(cfg=None).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(weights, map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_prune_idx(path):\n",
    "    lines = []\n",
    "    with open(path, 'r') as f:\n",
    "        file = f.readlines()\n",
    "        for line in file:\n",
    "            lines.append(line)\n",
    "            \n",
    "    idx = 0\n",
    "    prune_idx = []\n",
    "    for line in lines:\n",
    "        if \"):\" in line:\n",
    "            idx  += 1\n",
    "        if \"BatchNorm2d\" in line:\n",
    "            #print(idx, line)\n",
    "            prune_idx.append(idx)\n",
    "    \n",
    "    prune_idx = prune_idx[1:] # 去除第一个bn1层\n",
    "    return prune_idx\n",
    "\n",
    "model_name = \"./model.txt\"\n",
    "print(model, file=open(model_name, 'w'))\n",
    "prune_idx = obtain_prune_idx(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prune_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_bn(model, prune_idx):\n",
    "    size_list = [m.weight.data.shape[0] for idx, m in enumerate(model.modules()) if idx in prune_idx]\n",
    "    # bn_layer = [m for m in model.modules() if isinstance(m, nn.BatchNorm2d)]\n",
    "    bn_prune_layers = [m for idx, m in enumerate(model.modules()) if idx in prune_idx]\n",
    "    bn_weights = torch.zeros(sum(size_list))\n",
    "\n",
    "    index = 0\n",
    "    for module, size in zip(bn_prune_layers, size_list):\n",
    "        bn_weights[index:(index + size)] = module.weight.data.abs().clone()\n",
    "        index += size\n",
    "    sorted_bn = torch.sort(bn_weights)[0]\n",
    "    \n",
    "    return sorted_bn\n",
    "\n",
    "sorted_bn = sort_bn(model, prune_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0307e-09, 6.0363e-09, 4.6829e-08,  ..., 2.5850e-01, 2.8974e-01,\n",
       "        3.3852e-01])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_bn_mask(bn_module, thre):\n",
    "    if device != \"cpu\":\n",
    "        thre = thre.cuda()\n",
    "    mask = bn_module.weight.data.abs().ge(thre).float()\n",
    "\n",
    "    return mask\n",
    "\n",
    "def obtain_filters_mask(model, prune_idx, thre):\n",
    "    pruned = 0\n",
    "    bn_count = 0\n",
    "    total = 0\n",
    "    num_filters = []\n",
    "    pruned_filters = []\n",
    "    filters_mask = []\n",
    "    pruned_maskers = []\n",
    "    \n",
    "    for idx, module in enumerate(model.modules()):\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            if idx in prune_idx:\n",
    "                mask = obtain_bn_mask(module, thre).cpu().numpy()\n",
    "                remain = int(mask.sum())\n",
    "                pruned = pruned + mask.shape[0] - remain\n",
    "\n",
    "                if remain == 0: # 保证至少有一个channel\n",
    "                    # print(\"Channels would be all pruned!\")\n",
    "                    # raise Exception\n",
    "                    max_value = module.weight.data.abs().max()\n",
    "                    mask = obtain_bn_mask(module, max_value).cpu().numpy()\n",
    "                    remain = int(mask.sum())\n",
    "                    pruned = pruned + mask.shape[0] - remain\n",
    "                    bn_count += 1\n",
    "                print(f'layer index: {idx:>3d} \\t total channel: {mask.shape[0]:>4d} \\t '\n",
    "                      f'remaining channel: {remain:>4d}')\n",
    "                \n",
    "                pruned_filters.append(remain)\n",
    "                pruned_maskers.append(mask.copy())\n",
    "            else:\n",
    "                mask = np.ones(module.weight.data.shape)\n",
    "                remain = mask.shape[0]\n",
    "            \n",
    "            total += mask.shape[0]\n",
    "            num_filters.append(remain)\n",
    "            filters_mask.append(mask.copy())\n",
    "    \n",
    "    prune_ratio = pruned / total\n",
    "    print(f'Prune channels: {pruned}\\tPrune ratio: {prune_ratio:.3f}')\n",
    "\n",
    "    return pruned_filters, pruned_maskers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002)\n"
     ]
    }
   ],
   "source": [
    "def obtain_bn_threshold(model, sorted_bn, percentage):\n",
    "    thre_index = int(len(sorted_bn) * percentage)\n",
    "    thre = sorted_bn[thre_index]\n",
    "    \n",
    "    return thre\n",
    "\n",
    "threshold = obtain_bn_threshold(model, sorted_bn, percent)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer index:   9 \t total channel:   64 \t remaining channel:   23\n",
      "layer index:  11 \t total channel:   64 \t remaining channel:   27\n",
      "layer index:  13 \t total channel:  256 \t remaining channel:  101\n",
      "layer index:  23 \t total channel:  256 \t remaining channel:  121\n",
      "layer index:  26 \t total channel:   64 \t remaining channel:    8\n",
      "layer index:  28 \t total channel:   64 \t remaining channel:   16\n",
      "layer index:  30 \t total channel:  256 \t remaining channel:  111\n",
      "layer index:  33 \t total channel:   64 \t remaining channel:   18\n",
      "layer index:  35 \t total channel:   64 \t remaining channel:   11\n",
      "layer index:  37 \t total channel:  256 \t remaining channel:   94\n",
      "layer index:  41 \t total channel:  128 \t remaining channel:   55\n",
      "layer index:  43 \t total channel:  128 \t remaining channel:   91\n",
      "layer index:  45 \t total channel:  512 \t remaining channel:  223\n",
      "layer index:  55 \t total channel:  512 \t remaining channel:  260\n",
      "layer index:  58 \t total channel:  128 \t remaining channel:   52\n",
      "layer index:  60 \t total channel:  128 \t remaining channel:   66\n",
      "layer index:  62 \t total channel:  512 \t remaining channel:  258\n",
      "layer index:  65 \t total channel:  128 \t remaining channel:   75\n",
      "layer index:  67 \t total channel:  128 \t remaining channel:   78\n",
      "layer index:  69 \t total channel:  512 \t remaining channel:  239\n",
      "layer index:  72 \t total channel:  128 \t remaining channel:   74\n",
      "layer index:  74 \t total channel:  128 \t remaining channel:   80\n",
      "layer index:  76 \t total channel:  512 \t remaining channel:  234\n",
      "layer index:  80 \t total channel:  256 \t remaining channel:  132\n",
      "layer index:  82 \t total channel:  256 \t remaining channel:  202\n",
      "layer index:  84 \t total channel: 1024 \t remaining channel:  345\n",
      "layer index:  94 \t total channel: 1024 \t remaining channel:  356\n",
      "layer index:  97 \t total channel:  256 \t remaining channel:   23\n",
      "layer index:  99 \t total channel:  256 \t remaining channel:   29\n",
      "layer index: 101 \t total channel: 1024 \t remaining channel:  121\n",
      "layer index: 104 \t total channel:  256 \t remaining channel:   24\n",
      "layer index: 106 \t total channel:  256 \t remaining channel:   26\n",
      "layer index: 108 \t total channel: 1024 \t remaining channel:  120\n",
      "layer index: 111 \t total channel:  256 \t remaining channel:    8\n",
      "layer index: 113 \t total channel:  256 \t remaining channel:   15\n",
      "layer index: 115 \t total channel: 1024 \t remaining channel:  101\n",
      "layer index: 118 \t total channel:  256 \t remaining channel:   40\n",
      "layer index: 120 \t total channel:  256 \t remaining channel:   22\n",
      "layer index: 122 \t total channel: 1024 \t remaining channel:  258\n",
      "layer index: 125 \t total channel:  256 \t remaining channel:   22\n",
      "layer index: 127 \t total channel:  256 \t remaining channel:   17\n",
      "layer index: 129 \t total channel: 1024 \t remaining channel:  289\n",
      "layer index: 132 \t total channel:  256 \t remaining channel:   29\n",
      "layer index: 134 \t total channel:  256 \t remaining channel:   36\n",
      "layer index: 136 \t total channel: 1024 \t remaining channel:  242\n",
      "layer index: 139 \t total channel:  256 \t remaining channel:   24\n",
      "layer index: 141 \t total channel:  256 \t remaining channel:   21\n",
      "layer index: 143 \t total channel: 1024 \t remaining channel:  170\n",
      "layer index: 146 \t total channel:  256 \t remaining channel:    8\n",
      "layer index: 148 \t total channel:  256 \t remaining channel:    9\n",
      "layer index: 150 \t total channel: 1024 \t remaining channel:   84\n",
      "layer index: 153 \t total channel:  256 \t remaining channel:   29\n",
      "layer index: 155 \t total channel:  256 \t remaining channel:   24\n",
      "layer index: 157 \t total channel: 1024 \t remaining channel:  221\n",
      "layer index: 160 \t total channel:  256 \t remaining channel:   12\n",
      "layer index: 162 \t total channel:  256 \t remaining channel:    6\n",
      "layer index: 164 \t total channel: 1024 \t remaining channel:   81\n",
      "layer index: 167 \t total channel:  256 \t remaining channel:   14\n",
      "layer index: 169 \t total channel:  256 \t remaining channel:   13\n",
      "layer index: 171 \t total channel: 1024 \t remaining channel:  177\n",
      "layer index: 174 \t total channel:  256 \t remaining channel:    7\n",
      "layer index: 176 \t total channel:  256 \t remaining channel:   12\n",
      "layer index: 178 \t total channel: 1024 \t remaining channel:   89\n",
      "layer index: 181 \t total channel:  256 \t remaining channel:   14\n",
      "layer index: 183 \t total channel:  256 \t remaining channel:   16\n",
      "layer index: 185 \t total channel: 1024 \t remaining channel:   88\n",
      "layer index: 188 \t total channel:  256 \t remaining channel:   13\n",
      "layer index: 190 \t total channel:  256 \t remaining channel:   15\n",
      "layer index: 192 \t total channel: 1024 \t remaining channel:   69\n",
      "layer index: 195 \t total channel:  256 \t remaining channel:   40\n",
      "layer index: 197 \t total channel:  256 \t remaining channel:   32\n",
      "layer index: 199 \t total channel: 1024 \t remaining channel:  224\n",
      "layer index: 202 \t total channel:  256 \t remaining channel:   18\n",
      "layer index: 204 \t total channel:  256 \t remaining channel:   21\n",
      "layer index: 206 \t total channel: 1024 \t remaining channel:  195\n",
      "layer index: 209 \t total channel:  256 \t remaining channel:   35\n",
      "layer index: 211 \t total channel:  256 \t remaining channel:   42\n",
      "layer index: 213 \t total channel: 1024 \t remaining channel:  213\n",
      "layer index: 216 \t total channel:  256 \t remaining channel:   45\n",
      "layer index: 218 \t total channel:  256 \t remaining channel:   37\n",
      "layer index: 220 \t total channel: 1024 \t remaining channel:  264\n",
      "layer index: 223 \t total channel:  256 \t remaining channel:   37\n",
      "layer index: 225 \t total channel:  256 \t remaining channel:   37\n",
      "layer index: 227 \t total channel: 1024 \t remaining channel:  225\n",
      "layer index: 230 \t total channel:  256 \t remaining channel:   20\n",
      "layer index: 232 \t total channel:  256 \t remaining channel:   20\n",
      "layer index: 234 \t total channel: 1024 \t remaining channel:  184\n",
      "layer index: 237 \t total channel:  256 \t remaining channel:   53\n",
      "layer index: 239 \t total channel:  256 \t remaining channel:   46\n",
      "layer index: 241 \t total channel: 1024 \t remaining channel:  267\n",
      "layer index: 244 \t total channel:  256 \t remaining channel:   65\n",
      "layer index: 246 \t total channel:  256 \t remaining channel:   70\n",
      "layer index: 248 \t total channel: 1024 \t remaining channel:  304\n",
      "layer index: 252 \t total channel:  512 \t remaining channel:  147\n",
      "layer index: 254 \t total channel:  512 \t remaining channel:  265\n",
      "layer index: 256 \t total channel: 2048 \t remaining channel:  304\n",
      "layer index: 266 \t total channel: 2048 \t remaining channel:  306\n",
      "layer index: 269 \t total channel:  512 \t remaining channel:   65\n",
      "layer index: 271 \t total channel:  512 \t remaining channel:   60\n",
      "layer index: 273 \t total channel: 2048 \t remaining channel:  294\n",
      "layer index: 276 \t total channel:  512 \t remaining channel:   81\n",
      "layer index: 278 \t total channel:  512 \t remaining channel:   73\n",
      "layer index: 280 \t total channel: 2048 \t remaining channel:  273\n",
      "layer index: 284 \t total channel: 1024 \t remaining channel:  329\n",
      "layer index: 289 \t total channel:  512 \t remaining channel:  150\n",
      "Prune channels: 43315\tPrune ratio: 0.799\n"
     ]
    }
   ],
   "source": [
    "pruned_filters, pruned_maskers = obtain_filters_mask(model, prune_idx, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pruned_filters, file=open(\"ceiling.txt\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
